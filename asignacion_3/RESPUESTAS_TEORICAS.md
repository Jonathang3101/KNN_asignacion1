# Respuestas TeÃ³ricas - Ãrboles de DecisiÃ³n

## ğŸ“š Conceptos Fundamentales

### 1. Â¿QuÃ© es un Ãrbol de DecisiÃ³n?

Un **Ã¡rbol de decisiÃ³n** es un modelo de aprendizaje supervisado que realiza predicciones mediante una serie de decisiones binarias organizadas jerÃ¡rquicamente.

**Estructura:**
```
                    [RaÃ­z]
                 Â¿pixel[X] <= 127?
                /                  \
             SÃ­                     No
            /                        \
    [Nodo Interno]              [Nodo Interno]
    Â¿pixel[Y] <= 50?           Â¿pixel[Z] <= 200?
      /        \                  /          \
   [Hoja]   [Hoja]            [Hoja]      [Hoja]
   Clase 0  Clase 1           Clase 2     Clase 3
```

**Componentes:**
- **Nodo raÃ­z**: Primera decisiÃ³n
- **Nodos internos**: Decisiones intermedias
- **Hojas**: Predicciones finales (clases)
- **Ramas**: Caminos de decisiÃ³n

**Funcionamiento:**
1. Comienza en la raÃ­z
2. EvalÃºa condiciÃ³n (ej: Â¿pixel[X] <= valor?)
3. Sigue rama correspondiente (SÃ­/No)
4. Repite hasta llegar a una hoja
5. Retorna la clase de la hoja

---

### 2. Profundidad del Ãrbol (max_depth)

La **profundidad** es el nÃºmero mÃ¡ximo de niveles desde la raÃ­z hasta las hojas.

**Ejemplo:**
```
Profundidad 1:
    [RaÃ­z]
    /    \
 [Hoja] [Hoja]

Profundidad 2:
        [RaÃ­z]
       /      \
   [Nodo]    [Nodo]
   /   \      /   \
[Hoja][Hoja][Hoja][Hoja]

Profundidad 3:
            [RaÃ­z]
          /        \
      [Nodo]      [Nodo]
      /    \       /    \
  [Nodo][Nodo][Nodo][Nodo]
   / \    / \    / \    / \
  ...  ...  ...  ...  ...  ...
```

**Impacto de la profundidad:**

| Profundidad | Nodos mÃ¡ximos | Complejidad | Riesgo |
|-------------|---------------|-------------|--------|
| 1 | 3 | Muy baja | Underfitting |
| 5 | 63 | Baja | Posible underfitting |
| 10 | 2,047 | Media | Balance |
| 20 | 2,097,151 | Alta | Overfitting |
| âˆ | Ilimitado | Muy alta | Overfitting severo |

---

### 3. Underfitting (Subajuste)

**DefiniciÃ³n:**  
Modelo demasiado simple que no captura los patrones en los datos.

**CaracterÃ­sticas:**
- Accuracy bajo en **entrenamiento**
- Accuracy bajo en **validaciÃ³n/test**
- Diferencia pequeÃ±a entre train y val
- Modelo "demasiado general"

**Causas:**
- Profundidad muy baja
- Pocas caracterÃ­sticas
- Datos insuficientes
- Modelo inadecuado para el problema

**Ejemplo en MNIST:**
```python
# Profundidad 1 - Underfitting
modelo = DecisionTreeClassifier(max_depth=1)
# Resultado:
# Train accuracy: 0.45
# Val accuracy: 0.43
# â†’ Ambos bajos, no aprende patrones
```

**SÃ­ntomas:**
- "El modelo no aprende nada Ãºtil"
- Predicciones casi aleatorias
- No mejora con mÃ¡s datos

**SoluciÃ³n:**
- âœ“ Aumentar profundidad
- âœ“ Agregar mÃ¡s caracterÃ­sticas
- âœ“ Usar modelo mÃ¡s complejo
- âœ“ Feature engineering

**GrÃ¡fica tÃ­pica:**
```
Accuracy
   |
0.5|  â—â”€â”€â”€â”€â—  (Train)
   |  â—â”€â”€â”€â”€â—  (Val)
   |
   +â”€â”€â”€â”€â”€â”€â”€â”€â”€> Profundidad
     1   2
```

---

### 4. Overfitting (Sobreajuste)

**DefiniciÃ³n:**  
Modelo demasiado complejo que memoriza el ruido del entrenamiento en lugar de aprender patrones generales.

**CaracterÃ­sticas:**
- Accuracy **alto** en entrenamiento
- Accuracy **bajo** en validaciÃ³n/test
- **Gran diferencia** entre train y val
- Modelo "memoriza" en vez de "aprender"

**Causas:**
- Profundidad muy alta
- Demasiadas caracterÃ­sticas irrelevantes
- Datos de entrenamiento insuficientes
- Ruido en los datos

**Ejemplo en MNIST:**
```python
# Profundidad 50 - Overfitting
modelo = DecisionTreeClassifier(max_depth=50)
# Resultado:
# Train accuracy: 0.99
# Val accuracy: 0.75
# â†’ Gran diferencia, memoriza training
```

**SÃ­ntomas:**
- "Funciona perfecto en train, mal en test"
- Predicciones especÃ­ficas al training set
- No generaliza a datos nuevos

**SoluciÃ³n:**
- âœ“ Reducir profundidad
- âœ“ Poda (pruning)
- âœ“ RegularizaciÃ³n (min_samples_split, min_samples_leaf)
- âœ“ MÃ¡s datos de entrenamiento
- âœ“ Cross-validation
- âœ“ Ensemble methods (Random Forest)

**GrÃ¡fica tÃ­pica:**
```
Accuracy
   |
1.0|      â—â”€â”€â”€â”€â—  (Train)
   |
0.7|  â—â”€â”€â”€â”€â—      (Val)
   |
   +â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Profundidad
     10  20  30
```

---

### 5. Balance Ã“ptimo (Sweet Spot)

**DefiniciÃ³n:**  
Profundidad que maximiza la generalizaciÃ³n sin underfitting ni overfitting.

**CaracterÃ­sticas:**
- Accuracy **alto** en validaciÃ³n
- Diferencia **pequeÃ±a** entre train y val
- Modelo generaliza bien
- Balance sesgo-varianza

**CÃ³mo encontrarlo:**

1. **ExperimentaciÃ³n:**
   ```python
   profundidades = [1, 3, 5, 7, 10, 15, 20, 30]
   for prof in profundidades:
       modelo = DecisionTreeClassifier(max_depth=prof)
       # Evaluar y comparar
   ```

2. **ValidaciÃ³n cruzada:**
   ```python
   from sklearn.model_selection import GridSearchCV
   
   param_grid = {'max_depth': range(1, 31)}
   grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)
   grid.fit(X_train, y_train)
   mejor_prof = grid.best_params_['max_depth']
   ```

3. **AnÃ¡lisis de curvas:**
   - Graficar accuracy vs profundidad
   - Buscar donde val accuracy es mÃ¡ximo
   - Verificar que diferencia train-val sea pequeÃ±a

**Ejemplo ideal:**
```
Profundidad 10:
  Train accuracy: 0.88
  Val accuracy: 0.85
  Diferencia: 0.03 âœ“ (pequeÃ±a)
```

**GrÃ¡fica del balance:**
```
Accuracy
   |
1.0|        â—â”€â”€â”€â”€â”€â—  (Train)
   |      â—â”€â”€â”€â”€â”€â—    (Val)
0.8|    â—           
   |  â—             
   +â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Profundidad
     5   10  15  20
         â†‘
      Balance
```

---

## ğŸ¯ AplicaciÃ³n a MNIST

### CaracterÃ­sticas del Problema

**MNIST:**
- 784 features (pÃ­xeles)
- 10 clases (dÃ­gitos 0-9)
- Datos de alta dimensionalidad
- Patrones visuales complejos

**DesafÃ­os para Ã¡rboles:**
- Muchas caracterÃ­sticas â†’ Ã¡rbol muy grande
- PÃ­xeles correlacionados â†’ redundancia
- Patrones no lineales â†’ difÃ­cil de capturar

### Profundidades Recomendadas

| Profundidad | Uso | Resultado Esperado |
|-------------|-----|-------------------|
| 1-3 | Baseline | Underfitting (~40-50% acc) |
| 5-7 | ExploraciÃ³n | Moderado (~70-75% acc) |
| 10-15 | **Ã“ptimo** | **Bueno (~80-85% acc)** |
| 20-30 | Experimental | Overfitting (train>95%, val~80%) |
| >30 | No recomendado | Overfitting severo |

### ComparaciÃ³n con Otros Modelos

| Modelo | Accuracy MNIST | Complejidad | Interpretabilidad |
|--------|----------------|-------------|-------------------|
| Ãrbol (prof=10) | ~85% | Media | Alta |
| Random Forest | ~95% | Alta | Media |
| SVM | ~98% | Alta | Baja |
| CNN | **>99%** | Muy alta | Muy baja |

**ConclusiÃ³n:** Ãrboles son buenos para aprender, pero CNNs son mejores para imÃ¡genes.

---

## ğŸ“Š AnÃ¡lisis de MÃ©tricas

### Accuracy

**FÃ³rmula:**
```
Accuracy = (Predicciones Correctas) / (Total de Predicciones)
```

**InterpretaciÃ³n:**
- 0.90 = 90% de predicciones correctas
- 0.50 = 50% (aleatorio para 2 clases)
- 0.10 = 10% (para 10 clases, aleatorio serÃ­a ~10%)

**Limitaciones:**
- No funciona bien con clases desbalanceadas
- No distingue tipos de errores
- Puede ser engaÃ±oso

### Diferencia Train-Val

**FÃ³rmula:**
```
Diferencia = Accuracy_Train - Accuracy_Val
```

**InterpretaciÃ³n:**

| Diferencia | Significado |
|------------|-------------|
| < 0.05 | Excelente balance âœ“ |
| 0.05 - 0.10 | Buen balance âœ“ |
| 0.10 - 0.20 | Overfitting moderado âš ï¸ |
| > 0.20 | Overfitting severo âœ— |

**Ejemplo:**
```python
# Modelo A
train_acc = 0.88
val_acc = 0.85
diff = 0.03  # âœ“ Excelente

# Modelo B
train_acc = 0.99
val_acc = 0.75
diff = 0.24  # âœ— Overfitting severo
```

---

## ğŸ”§ TÃ©cnicas de Mejora

### 1. Poda (Pruning)

**Pre-pruning (antes de entrenar):**
```python
modelo = DecisionTreeClassifier(
    max_depth=10,              # Limitar profundidad
    min_samples_split=20,      # MÃ­nimo para dividir nodo
    min_samples_leaf=10,       # MÃ­nimo en hojas
    max_features='sqrt'        # Limitar features por split
)
```

**Post-pruning (despuÃ©s de entrenar):**
```python
# Cost complexity pruning
path = modelo.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas = path.ccp_alphas

# Probar diferentes alphas
for alpha in ccp_alphas:
    modelo_podado = DecisionTreeClassifier(ccp_alpha=alpha)
    # Evaluar
```

### 2. Ensemble Methods

**Random Forest:**
```python
from sklearn.ensemble import RandomForestClassifier

# MÃºltiples Ã¡rboles â†’ mejor generalizaciÃ³n
rf = RandomForestClassifier(
    n_estimators=100,    # 100 Ã¡rboles
    max_depth=10,
    random_state=42
)
```

**Ventajas:**
- Reduce overfitting
- Mejora accuracy
- MÃ¡s robusto

### 3. Feature Engineering

**Para MNIST:**
```python
# PCA para reducir dimensionalidad
from sklearn.decomposition import PCA

pca = PCA(n_components=50)  # 784 â†’ 50 features
X_reduced = pca.fit_transform(X)

# Entrenar con menos features
modelo = DecisionTreeClassifier(max_depth=10)
modelo.fit(X_reduced, y)
```

### 4. ValidaciÃ³n Cruzada

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(
    modelo, X, y, 
    cv=5,              # 5 folds
    scoring='accuracy'
)

print(f"Accuracy: {scores.mean():.4f} Â± {scores.std():.4f}")
```

---

## ğŸ’¡ Consejos PrÃ¡cticos

### Para Evitar Underfitting

1. âœ“ Aumentar profundidad gradualmente
2. âœ“ Verificar que el modelo aprende (train acc > random)
3. âœ“ Agregar mÃ¡s caracterÃ­sticas relevantes
4. âœ“ Usar modelos mÃ¡s complejos si es necesario

### Para Evitar Overfitting

1. âœ“ Usar validaciÃ³n cruzada
2. âœ“ Limitar profundidad
3. âœ“ Aplicar poda
4. âœ“ Aumentar datos de entrenamiento
5. âœ“ RegularizaciÃ³n (min_samples_*)
6. âœ“ Ensemble methods

### Para Encontrar el Balance

1. âœ“ Probar mÃºltiples profundidades
2. âœ“ Graficar train vs val accuracy
3. âœ“ Buscar donde val accuracy es mÃ¡ximo
4. âœ“ Verificar diferencia train-val pequeÃ±a
5. âœ“ Validar en test set final

---

## ğŸ“– Resumen Ejecutivo

| Concepto | DefiniciÃ³n Corta | SoluciÃ³n |
|----------|------------------|----------|
| **Underfitting** | Modelo muy simple | Aumentar complejidad |
| **Overfitting** | Modelo muy complejo | Reducir complejidad |
| **Balance** | Complejidad Ã³ptima | Experimentar y validar |
| **Profundidad** | Niveles del Ã¡rbol | Ajustar segÃºn datos |
| **GeneralizaciÃ³n** | Funciona en datos nuevos | ValidaciÃ³n cruzada |

**Regla de oro:**  
> "El mejor modelo no es el que mejor funciona en entrenamiento,  
> sino el que mejor generaliza a datos no vistos."

---

## ğŸ“ Preguntas Frecuentes

**P: Â¿CuÃ¡l es la mejor profundidad para MNIST?**  
R: TÃ­picamente 10-15, pero depende del tamaÃ±o del dataset y otras configuraciones.

**P: Â¿Por quÃ© no usar profundidad infinita?**  
R: CausarÃ­a overfitting severo. El Ã¡rbol memorizarÃ­a todo el training set.

**P: Â¿Los Ã¡rboles son buenos para imÃ¡genes?**  
R: No son ideales. CNNs son mucho mejores (>99% vs ~85% accuracy).

**P: Â¿CÃ³mo sÃ© si tengo overfitting?**  
R: Si train accuracy >> val accuracy (diferencia > 0.10).

**P: Â¿Puedo usar Ã¡rboles en producciÃ³n?**  
R: SÃ­, pero Random Forest o Gradient Boosting son mejores opciones.

---

**Fin del documento teÃ³rico**
