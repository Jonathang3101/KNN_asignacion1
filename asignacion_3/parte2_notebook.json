{
  "cells_parte2": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9️ Visualización del árbol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"PASO 9: VISUALIZACIÓN DEL ÁRBOL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Seleccionar el árbol más simple (profundidad 5)\n",
        "prof_visualizar = 5\n",
        "modelo_viz = modelos[prof_visualizar]\n",
        "\n",
        "print(f\"\\nVisualizando árbol con profundidad = {prof_visualizar}\")\n",
        "print(f\"(Los árboles más profundos son demasiado grandes para visualizar)\")\n",
        "\n",
        "# Crear figura grande\n",
        "fig, ax = plt.subplots(figsize=(20, 12))\n",
        "\n",
        "# Graficar árbol\n",
        "plot_tree(modelo_viz, \n",
        "         filled=True,\n",
        "         feature_names=[f'pixel{i}' for i in range(784)],\n",
        "         class_names=[str(i) for i in range(10)],\n",
        "         rounded=True,\n",
        "         fontsize=8,\n",
        "         ax=ax)\n",
        "\n",
        "plt.title(f'Árbol de Decisión (Profundidad = {prof_visualizar})', \n",
        "         fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('arbol_decision.png', dpi=200, bbox_inches='tight')\n",
        "print(\"\\n✓ Gráfica guardada: arbol_decision.png\")\n",
        "plt.show()\n",
        "\n",
        "# Análisis de características importantes\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANÁLISIS DEL ÁRBOL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Importancia de características\n",
        "importancias = modelo_viz.feature_importances_\n",
        "indices_importantes = np.argsort(importancias)[::-1][:10]\n",
        "\n",
        "print(\"\\nTop 10 píxeles más importantes:\")\n",
        "for i, idx in enumerate(indices_importantes, 1):\n",
        "    fila = idx // 28\n",
        "    col = idx % 28\n",
        "    print(f\"  {i}. Pixel {idx} (fila {fila}, col {col}): {importancias[idx]:.4f}\")\n",
        "\n",
        "# Visualizar píxeles importantes\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "mapa_importancia = importancias.reshape(28, 28)\n",
        "im = ax.imshow(mapa_importancia, cmap='hot', interpolation='nearest')\n",
        "ax.set_title('Mapa de Importancia de Píxeles', fontsize=14, fontweight='bold')\n",
        "plt.colorbar(im, ax=ax, label='Importancia')\n",
        "plt.tight_layout()\n",
        "plt.savefig('importancia_pixeles.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\n✓ Gráfica guardada: importancia_pixeles.png\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n  Comentarios:\")\n",
        "print(\"\\n¿Qué características usa el árbol para decidir?\")\n",
        "print(\"  - El árbol usa la intensidad de píxeles específicos.\")\n",
        "print(\"  - Los píxeles centrales suelen ser más importantes.\")\n",
        "print(\"  - Cada nodo pregunta: ¿pixel[X] <= valor?\")\n",
        "\n",
        "print(\"\\n¿Qué tan interpretable es un árbol para MNIST?\")\n",
        "print(\"  - Profundidad baja (5): Algo interpretable, pero limitado.\")\n",
        "print(\"  - Profundidad alta (20): Prácticamente imposible de interpretar.\")\n",
        "print(\"  - Los árboles no son el mejor modelo para imágenes.\")\n",
        "print(\"  - Redes neuronales (CNN) son más apropiadas para MNIST.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Conclusiones finales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"PASO 10: CONCLUSIONES FINALES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Resumen de resultados\n",
        "print(\"\\n RESUMEN DE RESULTADOS\")\n",
        "print(\"=\"*60)\n",
        "display(df_resultados)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANÁLISIS FINAL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n1  ¿Qué tan bien funcionan los árboles de decisión en MNIST?\")\n",
        "acc_promedio = df_resultados['Accuracy Val'].mean()\n",
        "print(f\"\\n   Accuracy promedio en validación: {acc_promedio:.4f} ({acc_promedio*100:.2f}%)\")\n",
        "if acc_promedio > 0.85:\n",
        "    print(\"   ✓ Desempeño bueno para un modelo simple.\")\n",
        "elif acc_promedio > 0.75:\n",
        "    print(\"   ✓ Desempeño aceptable, pero hay margen de mejora.\")\n",
        "else:\n",
        "    print(\"    Desempeño limitado. Otros modelos serían mejores.\")\n",
        "print(\"    Nota: CNNs logran >99% en MNIST.\")\n",
        "\n",
        "print(\"\\n2  ¿Cuál profundidad ofrece mejor balance?\")\n",
        "print(f\"\\n   Profundidad {mejor_prof}:\")\n",
        "print(f\"   - Accuracy Val: {mejor_acc:.4f}\")\n",
        "print(f\"   - Diferencia train-val: {df_resultados.loc[mejor_idx, 'Diferencia']:.4f}\")\n",
        "print(f\"   ✓ Mejor balance entre precisión y simplicidad.\")\n",
        "\n",
        "print(\"\\n3  ¿Qué modelo está subajustado (underfitting)?\")\n",
        "prof_min = df_resultados['Profundidad'].min()\n",
        "acc_min_idx = df_resultados['Profundidad'].idxmin()\n",
        "acc_min_train = df_resultados.loc[acc_min_idx, 'Accuracy Train']\n",
        "acc_min_val = df_resultados.loc[acc_min_idx, 'Accuracy Val']\n",
        "print(f\"\\n   Profundidad {prof_min}:\")\n",
        "print(f\"   - Accuracy Train: {acc_min_train:.4f}\")\n",
        "print(f\"   - Accuracy Val: {acc_min_val:.4f}\")\n",
        "if acc_min_train < 0.80 and acc_min_val < 0.80:\n",
        "    print(f\"   ✗ Muestra underfitting: ambos accuracy son bajos.\")\n",
        "    print(f\"   El modelo es demasiado simple para capturar patrones.\")\n",
        "else:\n",
        "    print(f\"   ✓ No muestra underfitting significativo.\")\n",
        "\n",
        "print(\"\\n4  ¿Qué modelo está sobreajustado (overfitting)?\")\n",
        "prof_max = df_resultados['Profundidad'].max()\n",
        "acc_max_idx = df_resultados['Profundidad'].idxmax()\n",
        "acc_max_train = df_resultados.loc[acc_max_idx, 'Accuracy Train']\n",
        "acc_max_val = df_resultados.loc[acc_max_idx, 'Accuracy Val']\n",
        "diff_max = df_resultados.loc[acc_max_idx, 'Diferencia']\n",
        "print(f\"\\n   Profundidad {prof_max}:\")\n",
        "print(f\"   - Accuracy Train: {acc_max_train:.4f}\")\n",
        "print(f\"   - Accuracy Val: {acc_max_val:.4f}\")\n",
        "print(f\"   - Diferencia: {diff_max:.4f}\")\n",
        "if diff_max > 0.10:\n",
        "    print(f\"   ✗ Muestra overfitting: gran diferencia train-val.\")\n",
        "    print(f\"   El modelo memoriza el training set.\")\n",
        "else:\n",
        "    print(f\"   ✓ Overfitting controlado.\")\n",
        "\n",
        "print(\"\\n5 Aprendizajes clave:\")\n",
        "print(\"\\n    Sobre el impacto de la profundidad:\")\n",
        "print(\"      - Profundidad baja → Modelo simple, puede subajustar\")\n",
        "print(\"      - Profundidad alta → Modelo complejo, puede sobreajustar\")\n",
        "print(\"      - Existe un punto óptimo que balancea ambos\")\n",
        "\n",
        "print(\"\\n   Sobre la generalización:\")\n",
        "print(\"      - Accuracy en train NO es suficiente\")\n",
        "print(\"      - Debemos evaluar en datos no vistos (validación/test)\")\n",
        "print(\"      - Gran diferencia train-val indica overfitting\")\n",
        "\n",
        "print(\"\\n   Sobre la importancia de evaluar múltiples modelos:\")\n",
        "print(\"      - No existe una profundidad 'correcta' universal\")\n",
        "print(\"      - Depende del dataset y problema específico\")\n",
        "print(\"      - Experimentar con varios valores es esencial\")\n",
        "print(\"      - La validación cruzada ayuda a encontrar el mejor\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RECOMENDACIONES FINALES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n✓ Para este problema (MNIST):\")\n",
        "print(f\"   - Usar profundidad {mejor_prof}\")\n",
        "print(f\"   - Considerar Random Forest para mejorar\")\n",
        "print(f\"   - Para mejor desempeño: usar CNN (>99% accuracy)\")\n",
        "\n",
        "print(\"\\n✓ Técnicas para mejorar árboles:\")\n",
        "print(\"   - Poda (pruning) para reducir overfitting\")\n",
        "print(\"   - Min_samples_split y min_samples_leaf\")\n",
        "print(\"   - Ensemble methods (Random Forest, Gradient Boosting)\")\n",
        "print(\"   - Feature engineering (PCA, selección de características)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANÁLISIS COMPLETADO ✓\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Matriz de Confusión (Bonus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matriz de confusión para el mejor modelo\n",
        "print(\"=\"*60)\n",
        "print(\"BONUS: MATRIZ DE CONFUSIÓN\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "mejor_modelo = modelos[mejor_prof]\n",
        "y_pred_mejor = mejor_modelo.predict(X_val)\n",
        "\n",
        "# Calcular matriz de confusión\n",
        "cm = confusion_matrix(y_val, y_pred_mejor)\n",
        "\n",
        "# Visualizar\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "           xticklabels=range(10), yticklabels=range(10),\n",
        "           cbar_kws={'label': 'Frecuencia'}, ax=ax)\n",
        "ax.set_xlabel('Predicción', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Real', fontsize=12, fontweight='bold')\n",
        "ax.set_title(f'Matriz de Confusión - Profundidad {mejor_prof}', \n",
        "            fontsize=14, fontweight='bold', pad=15)\n",
        "plt.tight_layout()\n",
        "plt.savefig('matriz_confusion.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\n✓ Gráfica guardada: matriz_confusion.png\")\n",
        "plt.show()\n",
        "\n",
        "# Reporte de clasificación\n",
        "print(\"\\nReporte de Clasificación:\")\n",
        "print(classification_report(y_val, y_pred_mejor, \n",
        "                          target_names=[f'Dígito {i}' for i in range(10)]))\n",
        "\n",
        "# Análisis de errores\n",
        "print(\"\\n  Análisis de errores:\")\n",
        "errores_por_clase = []\n",
        "for i in range(10):\n",
        "    total = np.sum(y_val == i)\n",
        "    correctos = cm[i, i]\n",
        "    errores = total - correctos\n",
        "    tasa_error = (errores / total) * 100 if total > 0 else 0\n",
        "    errores_por_clase.append((i, errores, tasa_error))\n",
        "    print(f\"  Dígito {i}: {errores} errores ({tasa_error:.1f}%)\")\n",
        "\n",
        "# Dígitos más confundidos\n",
        "print(\"\\n Pares de dígitos más confundidos:\")\n",
        "confusiones = []\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        if i != j and cm[i, j] > 0:\n",
        "            confusiones.append((i, j, cm[i, j]))\n",
        "\n",
        "confusiones.sort(key=lambda x: x[2], reverse=True)\n",
        "for i, (real, pred, count) in enumerate(confusiones[:5], 1):\n",
        "    print(f\"  {i}. {real} confundido con {pred}: {count} veces\")"
      ]
    }
  ]
}
