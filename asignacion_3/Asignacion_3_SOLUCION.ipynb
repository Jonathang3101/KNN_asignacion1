{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå≥ √Årboles de Decisi√≥n: Comparaci√≥n de Profundidades\n",
    "## Dataset: MNIST (D√≠gitos escritos a mano)\n",
    "\n",
    "### Introducci√≥n Te√≥rica\n",
    "\n",
    "**¬øQu√© es un √Årbol de Decisi√≥n?**\n",
    "\n",
    "Un √°rbol de decisi√≥n es un modelo de aprendizaje supervisado que toma decisiones dividiendo el espacio de datos mediante preguntas binarias:\n",
    "\n",
    "> ¬øLa caracter√≠stica X es mayor o menor que un valor?\n",
    "\n",
    "**Conceptos clave:**\n",
    "\n",
    "- **Profundidad (max_depth)**: N√∫mero m√°ximo de niveles del √°rbol\n",
    "- **Underfitting (Subajuste)**: Modelo demasiado simple, no captura patrones\n",
    "- **Overfitting (Sobreajuste)**: Modelo demasiado complejo, memoriza ruido\n",
    "- **Balance**: Profundidad √≥ptima que generaliza bien\n",
    "\n",
    "**Objetivo:** Comparar 3 √°rboles con diferentes profundidades para encontrar el balance √≥ptimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Carga y exploraci√≥n del dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PASO 2: CARGA Y EXPLORACI√ìN DEL DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cargar datasets\n",
    "train_df = pd.read_csv('../../datasets/mnist/mnist_train.csv')\n",
    "test_df = pd.read_csv('../../datasets/mnist/mnist_test.csv')\n",
    "\n",
    "print(f\"\\n‚úì Dataset de entrenamiento cargado: {train_df.shape}\")\n",
    "print(f\"‚úì Dataset de prueba cargado: {test_df.shape}\")\n",
    "\n",
    "# Exploraci√≥n\n",
    "print(f\"\\nInformaci√≥n del dataset de entrenamiento:\")\n",
    "print(f\"  - Filas: {train_df.shape[0]:,}\")\n",
    "print(f\"  - Columnas: {train_df.shape[1]}\")\n",
    "print(f\"  - Valores nulos: {train_df.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "display(train_df.head())\n",
    "\n",
    "print(f\"\\nEstad√≠sticas descriptivas:\")\n",
    "display(train_df.describe())\n",
    "\n",
    "# Descripci√≥n del dataset\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DESCRIPCI√ìN DEL DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìù ¬øQu√© representa cada fila?\")\n",
    "print(\"   Cada fila es una imagen de 28x28 p√≠xeles de un d√≠gito escrito a mano (0-9).\")\n",
    "print(\"   La imagen est√° 'aplanada' (flattened) en un vector de 784 valores.\")\n",
    "print(\"\\nüìù ¬øQu√© contienen las columnas?\")\n",
    "print(\"   - Columna 0 (label): El d√≠gito real (0-9) - VARIABLE OBJETIVO\")\n",
    "print(\"   - Columnas 1-784 (pixel0-pixel783): Intensidad de cada p√≠xel (0-255)\")\n",
    "print(\"   - Cada p√≠xel representa un punto en la imagen de 28x28\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Preparaci√≥n de las variables (X y y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PASO 3: PREPARACI√ìN DE VARIABLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Separar X (features) y y (target)\n",
    "# Asumiendo que la primera columna es 'label'\n",
    "X_train_full = train_df.iloc[:, 1:].values  # Todas las columnas excepto la primera\n",
    "y_train_full = train_df.iloc[:, 0].values   # Primera columna (label)\n",
    "\n",
    "X_test_full = test_df.iloc[:, 1:].values\n",
    "y_test_full = test_df.iloc[:, 0].values\n",
    "\n",
    "print(f\"\\n‚úì Variables preparadas:\")\n",
    "print(f\"  - X_train shape: {X_train_full.shape}\")\n",
    "print(f\"  - y_train shape: {y_train_full.shape}\")\n",
    "print(f\"  - X_test shape: {X_test_full.shape}\")\n",
    "print(f\"  - y_test shape: {y_test_full.shape}\")\n",
    "\n",
    "# Clases √∫nicas\n",
    "clases_unicas = np.unique(y_train_full)\n",
    "print(f\"\\n‚úì Clases √∫nicas en y: {clases_unicas}\")\n",
    "print(f\"‚úì N√∫mero de clases: {len(clases_unicas)}\")\n",
    "\n",
    "# Distribuci√≥n de clases\n",
    "print(f\"\\nDistribuci√≥n de clases en entrenamiento:\")\n",
    "for clase in clases_unicas:\n",
    "    count = np.sum(y_train_full == clase)\n",
    "    pct = (count / len(y_train_full)) * 100\n",
    "    print(f\"  D√≠gito {clase}: {count:,} ejemplos ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPLICACI√ìN\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìù ¬øQu√© significa cada fila en X?\")\n",
    "print(\"   Cada fila es un vector de 784 valores (28x28 p√≠xeles aplanados).\")\n",
    "print(\"   Cada valor representa la intensidad de gris de un p√≠xel (0=blanco, 255=negro).\")\n",
    "print(\"\\nüìù ¬øQu√© representa y?\")\n",
    "print(\"   y contiene las etiquetas: el d√≠gito real que representa cada imagen (0-9).\")\n",
    "print(\"   Es la variable que queremos predecir.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n de ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar algunos d√≠gitos\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    # Tomar un ejemplo de cada d√≠gito\n",
    "    idx = np.where(y_train_full == i)[0][0]\n",
    "    imagen = X_train_full[idx].reshape(28, 28)\n",
    "    \n",
    "    axes[i].imshow(imagen, cmap='gray')\n",
    "    axes[i].set_title(f'D√≠gito: {i}', fontsize=12, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Ejemplos de D√≠gitos MNIST', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('mnist_ejemplos.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n‚úì Gr√°fica guardada: mnist_ejemplos.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Divisi√≥n en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PASO 4: DIVISI√ìN TRAIN/TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ya tenemos train y test separados, pero vamos a usar una muestra m√°s peque√±a\n",
    "# para que el entrenamiento sea m√°s r√°pido (opcional)\n",
    "\n",
    "# Usar una muestra del dataset para acelerar (puedes ajustar)\n",
    "sample_size = 10000  # Usar 10,000 ejemplos de entrenamiento\n",
    "\n",
    "# Divisi√≥n 80/20 del dataset de entrenamiento\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full[:sample_size], \n",
    "    y_train_full[:sample_size],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full[:sample_size]\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Divisi√≥n completada:\")\n",
    "print(f\"  - Entrenamiento: {X_train.shape[0]:,} ejemplos ({(len(X_train)/(len(X_train)+len(X_val)))*100:.0f}%)\")\n",
    "print(f\"  - Validaci√≥n: {X_val.shape[0]:,} ejemplos ({(len(X_val)/(len(X_train)+len(X_val)))*100:.0f}%)\")\n",
    "print(f\"  - Test (separado): {X_test_full.shape[0]:,} ejemplos\")\n",
    "\n",
    "print(f\"\\n‚úì Estratificaci√≥n verificada:\")\n",
    "print(f\"  Distribuci√≥n en train:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for digit, count in zip(unique, counts):\n",
    "    print(f\"    D√≠gito {digit}: {count} ({count/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìù Nota: Se us√≥ random_state=42 para reproducibilidad.\")\n",
    "print(f\"üìù Estratificaci√≥n mantiene proporciones de cada d√≠gito en train y val.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Definir las profundidades a evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PASO 5: DEFINICI√ìN DE PROFUNDIDADES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Profundidades a evaluar\n",
    "profundidades = [5, 10, 20]\n",
    "\n",
    "print(f\"\\n‚úì Profundidades seleccionadas: {profundidades}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"JUSTIFICACI√ìN\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n¬øPor qu√© comparar varias profundidades?\")\n",
    "print(\"\\n1. MNIST tiene 784 caracter√≠sticas (p√≠xeles)\")\n",
    "print(\"   - Un √°rbol muy profundo puede memorizar el ruido (overfitting)\")\n",
    "print(\"   - Un √°rbol muy superficial puede no capturar patrones (underfitting)\")\n",
    "print(\"\\n2. Profundidad 5 (BAJA):\")\n",
    "print(\"   - √Årbol simple, pocas decisiones\")\n",
    "print(\"   - Puede subajustar (underfitting)\")\n",
    "print(\"   - R√°pido de entrenar\")\n",
    "print(\"\\n3. Profundidad 10 (MEDIA):\")\n",
    "print(\"   - Balance entre complejidad y generalizaci√≥n\")\n",
    "print(\"   - Probablemente el mejor punto\")\n",
    "print(\"\\n4. Profundidad 20 (ALTA):\")\n",
    "print(\"   - √Årbol muy complejo\")\n",
    "print(\"   - Puede sobreajustar (overfitting)\")\n",
    "print(\"   - Lento de entrenar\")\n",
    "print(\"\\n‚úì Comparar estas 3 nos permite encontrar el balance √≥ptimo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Entrenamiento de los modelos (tres profundidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PASO 6: ENTRENAMIENTO DE MODELOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Diccionario para guardar modelos y resultados\n",
    "modelos = {}\n",
    "resultados = []\n",
    "\n",
    "for profundidad in profundidades:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Entrenando √°rbol con profundidad = {profundidad}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Crear modelo\n",
    "    modelo = DecisionTreeClassifier(\n",
    "        max_depth=profundidad,\n",
    "        random_state=42,\n",
    "        criterion='gini'\n",
    "    )\n",
    "    \n",
    "    # Entrenar\n",
    "    print(f\"Entrenando...\")\n",
    "    modelo.fit(X_train, y_train)\n",
    "    print(f\"‚úì Entrenamiento completado\")\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred_train = modelo.predict(X_train)\n",
    "    y_pred_val = modelo.predict(X_val)\n",
    "    \n",
    "    # Calcular accuracy\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    acc_val = accuracy_score(y_val, y_pred_val)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    modelos[profundidad] = modelo\n",
    "    resultados.append({\n",
    "        'Profundidad': profundidad,\n",
    "        'Accuracy Train': acc_train,\n",
    "        'Accuracy Val': acc_val,\n",
    "        'Diferencia': acc_train - acc_val\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nResultados:\")\n",
    "    print(f\"  - Accuracy Train: {acc_train:.4f} ({acc_train*100:.2f}%)\")\n",
    "    print(f\"  - Accuracy Val:   {acc_val:.4f} ({acc_val*100:.2f}%)\")\n",
    "    print(f\"  - Diferencia:     {acc_train - acc_val:.4f}\")\n",
    "    print(f\"  - Nodos del √°rbol: {modelo.tree_.node_count}\")\n",
    "    print(f\"  - Hojas del √°rbol: {modelo.get_n_leaves()}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úì Todos los modelos entrenados exitosamente\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Tabla de comparaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PASO 7: TABLA COMPARATIVA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear DataFrame\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "print(\"\\nTabla de Resultados:\")\n",
    "display(df_resultados.style.format({\n",
    "    'Accuracy Train': '{:.4f}',\n",
    "    'Accuracy Val': '{:.4f}',\n",
    "    'Diferencia': '{:.4f}'\n",
    "}).background_gradient(subset=['Accuracy Val'], cmap='RdYlGn'))\n",
    "\n",
    "# An√°lisis\n",
    "mejor_idx = df_resultados['Accuracy Val'].idxmax()\n",
    "mejor_prof = df_resultados.loc[mejor_idx, 'Profundidad']\n",
    "mejor_acc = df_resultados.loc[mejor_idx, 'Accuracy Val']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AN√ÅLISIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n‚úì Mejor profundidad: {mejor_prof} (Accuracy Val = {mejor_acc:.4f})\")\n",
    "\n",
    "print(\"\\nüìä Observaciones:\")\n",
    "for idx, row in df_resultados.iterrows():\n",
    "    prof = row['Profundidad']\n",
    "    diff = row['Diferencia']\n",
    "    \n",
    "    print(f\"\\nProfundidad {prof}:\")\n",
    "    if diff < 0.05:\n",
    "        print(f\"  ‚úì Diferencia peque√±a ({diff:.4f}) - Buen balance\")\n",
    "    elif diff < 0.15:\n",
    "        print(f\"  ‚ö†Ô∏è Diferencia moderada ({diff:.4f}) - Posible sobreajuste leve\")\n",
    "    else:\n",
    "        print(f\"  ‚úó Diferencia grande ({diff:.4f}) - Sobreajuste evidente\")\n",
    "\n",
    "print(\"\\nüìù Interpretaci√≥n:\")\n",
    "print(\"  - Diferencia grande (train >> val) ‚Üí Overfitting\")\n",
    "print(\"  - Accuracy bajo en ambos ‚Üí Underfitting\")\n",
    "print(\"  - Diferencia peque√±a y accuracy alto ‚Üí Balance √≥ptimo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Gr√°fica de desempe√±o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PASO 8: GR√ÅFICA DE DESEMPE√ëO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Graficar l√≠neas\n",
    "ax.plot(df_resultados['Profundidad'], df_resultados['Accuracy Train'], \n",
    "        marker='o', linewidth=2.5, markersize=10, label='Train', color='blue')\n",
    "ax.plot(df_resultados['Profundidad'], df_resultados['Accuracy Val'], \n",
    "        marker='s', linewidth=2.5, markersize=10, label='Validaci√≥n', color='red')\n",
    "\n",
    "# Configuraci√≥n\n",
    "ax.set_xlabel('Profundidad del √Årbol', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Desempe√±o de √Årboles de Decisi√≥n vs Profundidad\\nMNIST Dataset', \n",
    "            fontsize=14, fontweight='bold', pad=15)\n",
    "ax.legend(fontsize=11, loc='best')\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "ax.set_xticks(df_resultados['Profundidad'])\n",
    "\n",
    "# A√±adir valores en los puntos\n",
    "for idx, row in df_resultados.iterrows():\n",
    "    ax.annotate(f\"{row['Accuracy Train']:.3f}\", \n",
    "               (row['Profundidad'], row['Accuracy Train']),\n",
    "               textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=9)\n",
    "    ax.annotate(f\"{row['Accuracy Val']:.3f}\", \n",
    "               (row['Profundidad'], row['Accuracy Val']),\n",
    "               textcoords=\"offset points\", xytext=(0,-15), ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('desempeno_profundidad.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n‚úì Gr√°fica guardada: desempeno_profundidad.png\")\n",
    "plt.show()\n",
    "\n",
    "# Interpretaci√≥n\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERPRETACI√ìN DE LA GR√ÅFICA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n‚ùì ¬øAumentar profundidad siempre mejora el modelo?\")\n",
    "if df_resultados['Accuracy Val'].is_monotonic_increasing:\n",
    "    print(\"   ‚úì S√≠, en este caso el accuracy de validaci√≥n aumenta con la profundidad.\")\n",
    "else:\n",
    "    print(\"   ‚úó No, el accuracy de validaci√≥n no siempre mejora.\")\n",
    "    print(\"   Aumentar profundidad puede causar overfitting.\")\n",
    "\n",
    "print(\"\\n‚ùì ¬øEn qu√© punto comienza el sobreajuste?\")\n",
    "max_diff_idx = df_resultados['Diferencia'].idxmax()\n",
    "prof_overfit = df_resultados.loc[max_diff_idx, 'Profundidad']\n",
    "print(f\"   La mayor diferencia train-val ocurre en profundidad {prof_overfit}.\")\n",
    "print(f\"   Esto sugiere que el sobreajuste es m√°s evidente ah√≠.\")\n",
    "\n",
    "print(\"\\n‚ùì ¬øCu√°l profundidad logra el mejor balance?\")\n",
    "print(f\"   Profundidad {mejor_prof} tiene el mejor accuracy de validaci√≥n.\")\n",
    "mejor_diff = df_resultados.loc[mejor_idx, 'Diferencia']\n",
    "print(f\"   Con una diferencia train-val de {mejor_diff:.4f}.\")\n",
    "if mejor_diff < 0.1:\n",
    "    print(f\"   ‚úì Excelente balance entre sesgo y varianza.\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Hay algo de sobreajuste, pero es el mejor disponible.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
