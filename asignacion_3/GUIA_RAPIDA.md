# ðŸš€ GuÃ­a RÃ¡pida - AsignaciÃ³n 3

## âš¡ Inicio RÃ¡pido (5 minutos)

### 1. Instalar dependencias
```bash
cd IA/Asignaciones/Asignacion_3
pip install -r requirements.txt
```

### 2. Test rÃ¡pido
```bash
python test_rapido.py
```

### 3. Ejecutar notebook
```bash
jupyter notebook Asignacion_3_SOLUCION.ipynb
```

Luego: **Cell â†’ Run All**

---

## ðŸ“‹ Checklist de Entrega

- [ ] Notebook ejecutado completamente
- [ ] Todas las grÃ¡ficas generadas
- [ ] Tabla comparativa completa
- [ ] Conclusiones escritas
- [ ] Respuestas a preguntas teÃ³ricas

---

## ðŸ“Š Resultados Esperados

### GrÃ¡ficas (5 archivos PNG)

1. âœ… `mnist_ejemplos.png` - Ejemplos de dÃ­gitos
2. âœ… `desempeno_profundidad.png` - Accuracy vs Profundidad
3. âœ… `arbol_decision.png` - VisualizaciÃ³n del Ã¡rbol
4. âœ… `importancia_pixeles.png` - Mapa de calor
5. âœ… `matriz_confusion.png` - Matriz de confusiÃ³n

### Tabla de Resultados

| Profundidad | Acc Train | Acc Val | Diferencia |
|-------------|-----------|---------|------------|
| 5 | ~0.75 | ~0.72 | ~0.03 |
| 10 | ~0.88 | ~0.85 | ~0.03 |
| 20 | ~0.99 | ~0.82 | ~0.17 |

---

## ðŸŽ¯ Puntos Clave para la PresentaciÃ³n

### 1. IntroducciÃ³n (2 min)
- QuÃ© es un Ã¡rbol de decisiÃ³n
- Concepto de profundidad
- Underfitting vs Overfitting

### 2. MetodologÃ­a (2 min)
- Dataset MNIST (784 pÃ­xeles, 10 clases)
- 3 profundidades: 5, 10, 20
- DivisiÃ³n 80/20 estratificada

### 3. Resultados (3 min)
- Mostrar tabla comparativa
- GrÃ¡fica de desempeÃ±o
- Identificar mejor modelo

### 4. AnÃ¡lisis (2 min)
- Profundidad 5: Posible underfitting
- Profundidad 10: Balance Ã³ptimo âœ“
- Profundidad 20: Overfitting evidente

### 5. Conclusiones (1 min)
- Mejor profundidad: 10
- Accuracy: ~85%
- Ãrboles funcionan, pero CNNs son mejores

---

## â“ Preguntas Frecuentes

**P: Â¿Por quÃ© usar solo 3 profundidades?**  
R: Para demostrar claramente underfitting, balance y overfitting.

**P: Â¿Puedo usar mÃ¡s datos?**  
R: SÃ­, pero el entrenamiento serÃ¡ mÃ¡s lento. 10,000 ejemplos es suficiente.

**P: Â¿Por quÃ© no profundidad 1?**  
R: SerÃ­a demasiado simple (underfitting extremo). Profundidad 5 ya lo demuestra.

**P: Â¿QuÃ© accuracy es "bueno"?**  
R: Para Ã¡rboles en MNIST: 80-85% es bueno. CNNs logran >99%.

**P: Â¿CÃ³mo interpreto la diferencia train-val?**  
R: < 0.05 = excelente, 0.05-0.10 = bueno, > 0.10 = overfitting.

---

## ðŸ”§ Troubleshooting

### Error: "No module named 'sklearn'"
```bash
pip install scikit-learn
```

### Error: "File not found: mnist_train.csv"
Verifica que estÃ¡s en el directorio correcto:
```bash
cd IA/Asignaciones/Asignacion_3
ls  # Debe mostrar mnist_train.csv
```

### Notebook muy lento
Reduce sample_size en el cÃ³digo:
```python
sample_size = 5000  # En vez de 10000
```

### GrÃ¡ficas no aparecen
Agrega al inicio del notebook:
```python
%matplotlib inline
```

---

## ðŸ“š Recursos Adicionales

- **README.md**: DocumentaciÃ³n completa
- **RESPUESTAS_TEORICAS.md**: Conceptos detallados
- **solucion_completa.py**: Script alternativo
- **test_rapido.py**: VerificaciÃ³n rÃ¡pida

---

## âœ… Criterios de Ã‰xito

### MÃ­nimo (70 pts)
- âœ“ CÃ³digo ejecuta sin errores
- âœ“ 3 modelos entrenados
- âœ“ Tabla comparativa
- âœ“ Conclusiones bÃ¡sicas

### Excelente (90+ pts)
- âœ“ Todo lo anterior
- âœ“ Todas las grÃ¡ficas generadas
- âœ“ AnÃ¡lisis profundo
- âœ“ Respuestas teÃ³ricas completas
- âœ“ VisualizaciÃ³n del Ã¡rbol
- âœ“ Matriz de confusiÃ³n

---

## ðŸŽ“ Tips para MÃ¡xima CalificaciÃ³n

1. **Ejecuta TODO el notebook** - No dejes celdas sin ejecutar
2. **Comenta tus observaciones** - Agrega anÃ¡lisis personal
3. **Genera todas las grÃ¡ficas** - Son parte de la evaluaciÃ³n
4. **Responde las preguntas teÃ³ricas** - Demuestra comprensiÃ³n
5. **Revisa la rÃºbrica** - AsegÃºrate de cubrir todos los puntos

---

**Tiempo estimado total: 30-45 minutos**

Â¡Ã‰xito! ðŸš€
