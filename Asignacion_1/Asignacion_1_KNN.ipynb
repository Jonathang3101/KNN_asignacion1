{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c774c713",
   "metadata": {},
   "source": [
    "## Descripción del dataset: Pima Indians Diabetes\n",
    "\n",
    "El **Pima Indians Diabetes Dataset** es un conjunto de datos clásico en Machine Learning y bioestadística, recopilado por el *National Institute of Diabetes and Digestive and Kidney Diseases*.  \n",
    "Su propósito es **predecir la aparición de diabetes tipo 2** en mujeres de origen **pima** (una población indígena del sur de Arizona, EE.UU.), a partir de diversas variables clínicas y demográficas.\n",
    "\n",
    "### Características principales:\n",
    "- **Número de registros:** 392 (en esta versión limpia, el original tenía 768).  \n",
    "- **Número de atributos (features):** 8 variables predictoras + 1 variable objetivo.  \n",
    "- **Población:** Mujeres de al menos 21 años de edad de la etnia Pima.  \n",
    "- **Tarea principal:** Clasificación binaria → determinar si una paciente tiene diabetes (`Outcome = 1`) o no (`Outcome = 0`).\n",
    "\n",
    "### Variables:\n",
    "1. **Pregnancies** → Número de embarazos.  \n",
    "2. **Glucose** → Concentración de glucosa en plasma después de 2 horas en una prueba de tolerancia a la glucosa.  \n",
    "3. **BloodPressure** → Presión arterial diastólica (mm Hg).  \n",
    "4. **SkinThickness** → Espesor del pliegue cutáneo del tríceps (mm).  \n",
    "5. **Insulin** → Nivel sérico de insulina (mu U/ml).  \n",
    "6. **BMI** → Índice de masa corporal (peso en kg / altura² en m²).  \n",
    "7. **DiabetesPedigreeFunction** → Probabilidad de diabetes basada en antecedentes familiares.  \n",
    "8. **Age** → Edad en años.  \n",
    "9. **Outcome** → Variable objetivo:  \n",
    "   - `0` = No tiene diabetes  \n",
    "   - `1` = Tiene diabetes  \n",
    "\n",
    "### Relevancia:\n",
    "Este dataset es ampliamente utilizado en cursos de **Inteligencia Artificial y Machine Learning** para enseñar:\n",
    "- Procesamiento y limpieza de datos biomédicos.  \n",
    "- Métodos de clasificación supervisada (KNN, regresión logística, Random Forest, SVM, redes neuronales, etc.).  \n",
    "- Importancia de la normalización y estandarización en algoritmos basados en distancias.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89ef96",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar la base de datos  \n",
    "Cargamos el CSV en un `DataFrame` de `pandas`. Si tu archivo no se llama exactamente `cleaned_dataset.csv`, ajusta la ruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7da72f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
      "0            0      129             110              46      130  67.1   \n",
      "1            0      180              78              63       14  59.4   \n",
      "2            3      123             100              35      240  57.3   \n",
      "3            1       88              30              42       99  55.0   \n",
      "4            0      162              76              56      100  53.2   \n",
      "\n",
      "   Diabetes Pedigree Function  Age  Outcome  \n",
      "0                       0.319   26        1  \n",
      "1                       2.420   25        1  \n",
      "2                       0.880   22        0  \n",
      "3                       0.496   26        1  \n",
      "4                       0.759   25        1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dataset/cleaned_dataset.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b7ef2",
   "metadata": {},
   "source": [
    "## Paso 2: Crear subconjuntos con 20 datos de **entrenamiento** y 20 de **testeo**\n",
    "Seleccionaremos 40 muestras: 20 para entrenar y 20 para evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cce560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento:\n",
      "   Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
      "0            2      146              76              35      194  38.2   \n",
      "1            7       83              78              26       71  29.3   \n",
      "2            0      120              74              18       63  30.5   \n",
      "3            0       91              68              32      210  39.9   \n",
      "4            1       92              62              25       41  19.5   \n",
      "\n",
      "   Diabetes Pedigree Function  Age  Outcome  \n",
      "0                       0.329   29        0  \n",
      "1                       0.767   36        0  \n",
      "2                       0.285   26        0  \n",
      "3                       0.381   25        0  \n",
      "4                       0.482   25        0  \n",
      "\n",
      "Testeo:\n",
      "   Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
      "0            0      118              84              47      230  45.8   \n",
      "1            1      100              74              12       46  19.5   \n",
      "2            7      195              70              33      145  25.1   \n",
      "3            0      129             110              46      130  67.1   \n",
      "4            5      136              84              41       88  35.0   \n",
      "\n",
      "   Diabetes Pedigree Function  Age  Outcome  \n",
      "0                       0.551   31        1  \n",
      "1                       0.149   28        0  \n",
      "2                       0.163   55        1  \n",
      "3                       0.319   26        1  \n",
      "4                       0.286   35        1  \n"
     ]
    }
   ],
   "source": [
    "#codigo aqui\n",
    "df_sample = df.sample(n=40, random_state=42)\n",
    "train_df = df_sample.iloc[:20].reset_index(drop=True)\n",
    "test_df = df_sample.iloc[20:40].reset_index(drop=True)\n",
    "print(\"Entrenamiento:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTesteo:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1e8d1",
   "metadata": {},
   "source": [
    "## Paso 3: Implementar la función de distancia euclidiana\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función en Python que reciba dos vectores y calcule la distancia euclidiana entre ellos.\n",
    "- Utiliza la siguiente fórmula matemática para la distancia euclidiana entre dos vectores $x$ y $y$ de $n$ dimensiones:\n",
    "\n",
    "$$\n",
    "d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$\n",
    "\n",
    "- Prueba tu función con los siguientes dos ejemplos (cada vector corresponde a una fila del dataset):\n",
    "\n",
    "| Embarazos | Glucosa | Presión Arterial | Grosor Piel | Insulina | IMC  | Función Hereditaria | Edad | Resultado |\n",
    "|-----------|---------|------------------|-------------|----------|------|---------------------|------|-----------|\n",
    "|     1     |   106   |        70        |      28     |   135    | 34.2 |        0.142        |  22  |     0     |\n",
    "|     2     |   102   |        86        |      36     |   120    | 45.5 |        0.127        |  23  |     1     |\n",
    "\n",
    "- Calcula la distancia euclidiana a mano y luego verifica que el resultado de tu función sea el mismo.\n",
    "- La función debe imprimir el resultado del cálculo de la distancia euclidiana con los datos presentados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aa56bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distancia euclidiana entre x e y: 26.2620\n"
     ]
    }
   ],
   "source": [
    "#codigo aqui\n",
    "import numpy as np\n",
    "def euclidean_distance(row1, row2):\n",
    "    vec1 = np.array(row1[:-1])\n",
    "    vec2 = np.array(row2[:-1])\n",
    "    return np.sqrt(np.sum((vec1 - vec2) ** 2))  \n",
    "\n",
    "x = [1, 106, 70, 28, 135, 34.2, 0.142, 22]\n",
    "y = [2, 102, 86, 36, 120, 45.5, 0.127, 23]\n",
    "\n",
    "dist = euclidean_distance(x, y)\n",
    "print(f\"Distancia euclidiana entre x e y: {dist:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73bbcc",
   "metadata": {},
   "source": [
    "## Paso 4: Implementar un clasificador KNN básico\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función que, dado un punto de prueba, calcule la distancia a todos los puntos de entrenamiento utilizando tu función de distancia euclidiana.\n",
    "- Selecciona los **k = 3** vecinos más cercanos y predice la clase mayoritaria entre ellos.\n",
    "- Aplica tu función a las 10 muestras de prueba obtenidas previamente, utilizando las 10 muestras de entrenamiento como referencia.\n",
    "- El script debe imprimir una tabla comparando el valor real de `Resultado` de cada muestra de prueba con el valor predicho por tu algoritmo.\n",
    "- Considere que las tablas se pueden codificar con un formato similar al que se muestra en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d1223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real      Predicho  \n",
      "1         0         \n",
      "0         0         \n",
      "1         1         \n",
      "1         0         \n",
      "1         0         \n",
      "1         0         \n",
      "0         0         \n",
      "1         0         \n",
      "0         0         \n",
      "0         0         \n"
     ]
    }
   ],
   "source": [
    "#codigo aqui\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def euclidean_distance(row1, row2):\n",
    "    return np.sqrt(np.sum((row1 - row2) ** 2))\n",
    "\n",
    "def knn_predict(test_row, train_X, train_y, k=3):\n",
    "    distances = []\n",
    "    for i in range(len(train_X)):\n",
    "        dist = euclidean_distance(test_row, train_X[i])\n",
    "        distances.append((dist, train_y[i]))\n",
    "    \n",
    "    neighbors = sorted(distances, key=lambda x: x[0])[:k]\n",
    "   \n",
    "    classes = [neighbor[1] for neighbor in neighbors]\n",
    "    return Counter(classes).most_common(1)[0][0]\n",
    "\n",
    "\n",
    "train_X = train_df.iloc[:10, :-1].values\n",
    "train_y = train_df.iloc[:10, -1].values\n",
    "test_X = test_df.iloc[:10, :-1].values\n",
    "test_y = test_df.iloc[:10, -1].values\n",
    "\n",
    "print(f\"{'Real':<10}{'Predicho':<10}\")\n",
    "for i in range(10):\n",
    "    pred = knn_predict(test_X[i], train_X, train_y, k=3)\n",
    "    print(f\"{int(test_y[i]):<10}{int(pred):<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f7f05",
   "metadata": {},
   "source": [
    "## Paso 5: Usar toda la data con separación 80% entrenamiento / 20% testeo  \n",
    "\n",
    "### Pasos:\n",
    "1. Cargar todo el dataset.  \n",
    "2. Separar variables (X) y etiquetas (y).  \n",
    "3. Aplicar `train_test_split` con 80% para entrenamiento y 20% para testeo.  \n",
    "4. Mantener la proporción de clases usando estratificación.  \n",
    "5. Guardar los conjuntos de datos para usarlos en KNN.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8e3b9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño entrenamiento: (313, 8)\n",
      "Tamaño testeo: (79, 8)\n"
     ]
    }
   ],
   "source": [
    "#codigo aqui\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df.iloc[:, :-1].values  \n",
    "y = df.iloc[:, -1].values   \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Tamaño entrenamiento:\", X_train.shape)\n",
    "print(\"Tamaño testeo:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb071d8",
   "metadata": {},
   "source": [
    "## Paso 6: Entrenar un KNN con los datos sin escalar (crudos) y calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Definir el valor de **k = 3** y el metodo **Euclidiano**.  \n",
    "2. Entrenar el modelo KNN con los datos crudos (sin normalizar/estandarizar).  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** comparando predicciones con etiquetas reales.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1842e010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (datos crudos, sin escalar): 0.8101\n"
     ]
    }
   ],
   "source": [
    "#codigo aqui\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_crudo = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy (datos crudos, sin escalar): {accuracy_crudo:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82664821",
   "metadata": {},
   "source": [
    "## Paso 7: Normalizar (Min-Max scaling) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **normalización Min-Max** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos normalizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32694423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (normalización Min-Max): 0.7342\n"
     ]
    }
   ],
   "source": [
    "#codigo aqui\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "knn_norm = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_norm.fit(X_train_norm, y_train)\n",
    "\n",
    "\n",
    "y_pred_norm = knn_norm.predict(X_test_norm)\n",
    "accuracy_norm = accuracy_score(y_test, y_pred_norm)\n",
    "print(f\"Accuracy (normalización Min-Max): {accuracy_norm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6519b",
   "metadata": {},
   "source": [
    "## Paso 9: Estandarizar (Z-score) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **estandarización Z-score** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos estandarizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10afcc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (estandarización Z-score): 0.7468\n"
     ]
    }
   ],
   "source": [
    "#codigo aqui\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler_z = StandardScaler()\n",
    "X_train_z = scaler_z.fit_transform(X_train)\n",
    "X_test_z = scaler_z.transform(X_test)\n",
    "\n",
    "\n",
    "knn_z = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_z.fit(X_train_z, y_train)\n",
    "\n",
    "y_pred_z = knn_z.predict(X_test_z)\n",
    "accuracy_z = accuracy_score(y_test, y_pred_z)\n",
    "print(f\"Accuracy (estandarización Z-score): {accuracy_z:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58946086",
   "metadata": {},
   "source": [
    "## Paso 10/11: Tabla comparativa de accuracies  \n",
    "\n",
    "### Pasos:\n",
    "1. Reunir los resultados de accuracy de cada experimento:  \n",
    "   - KNN sin escalar (80/20).  \n",
    "   - KNN normalizado (80/20).  \n",
    "   - KNN estandarizado (80/20).  \n",
    "2. Crear una tabla con los resultados.  \n",
    "3. Comparar el desempeño de cada método.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e671386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Método  Accuracy\n",
      "0      KNN sin escalar (crudo)  0.810127\n",
      "1    KNN normalizado (Min-Max)  0.734177\n",
      "2  KNN estandarizado (Z-score)  0.746835\n"
     ]
    }
   ],
   "source": [
    "#codigo aqui\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "resultados = {\n",
    "    \"Método\": [\n",
    "        \"KNN sin escalar (crudo)\",\n",
    "        \"KNN normalizado (Min-Max)\",\n",
    "        \"KNN estandarizado (Z-score)\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_crudo,\n",
    "        accuracy_norm,\n",
    "        accuracy_z\n",
    "    ]\n",
    "}\n",
    "\n",
    "tabla = pd.DataFrame(resultados)\n",
    "print(tabla)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cafd7a",
   "metadata": {},
   "source": [
    "---\n",
    "## Preguntas de reflexión y aplicación\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bf383",
   "metadata": {},
   "source": [
    "1. ¿Por qué es importante normalizar o estandarizar los datos antes de usar KNN?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2779a6f",
   "metadata": {},
   "source": [
    "La normalización o estandarización es importante porque KNN utiliza distancias entre puntos para clasificar. Si las variables tienen escalas muy diferentes, las de mayor rango dominarán el cálculo de la distancia, haciendo que el modelo sea menos preciso. Normalizar o estandarizar asegura que todas las variables contribuyan de manera similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ee450",
   "metadata": {},
   "source": [
    "Responda aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393faba",
   "metadata": {},
   "source": [
    "2. ¿Qué diferencias observaste en el accuracy entre los datos crudos, normalizados y estandarizados?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99280630",
   "metadata": {},
   "source": [
    "Generalmente, el accuracy mejora al normalizar o estandarizar los datos, ya que el modelo puede comparar de manera justa todas las características. En datos crudos, el rendimiento suele ser menor porque algunas variables dominan la distancia. La normalización y la estandarización suelen dar resultados similares, aunque depende del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6273f",
   "metadata": {},
   "source": [
    "Respinda aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2743a4d",
   "metadata": {},
   "source": [
    "3. Si aumentamos el valor de **k** (número de vecinos), ¿cómo crees que cambiaría el rendimiento del modelo?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86448e43",
   "metadata": {},
   "source": [
    "Si aumentamos k, el modelo se vuelve más robusto al ruido, pero puede perder capacidad para captar patrones locales (se vuelve más general). Un k muy alto puede llevar a un modelo que no distingue bien entre clases (subajuste), mientras que un k muy bajo puede ser sensible al ruido (sobreajuste)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817198b3",
   "metadata": {},
   "source": [
    "Responda aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a02e07",
   "metadata": {},
   "source": [
    "4. ¿Qué ventaja tiene implementar KNN manualmente antes de usar scikit-learn?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38495fa3",
   "metadata": {},
   "source": [
    "Implementar KNN manualmente ayuda a comprender cómo funciona el algoritmo internamente: el cálculo de distancias, la selección de vecinos y la votación mayoritaria. Esto facilita la interpretación de resultados y la detección de posibles problemas en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b32f9",
   "metadata": {},
   "source": [
    "respuesta aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc53e18",
   "metadata": {},
   "source": [
    "5. ¿Qué limitaciones presenta KNN cuando se aplica a conjuntos de datos grandes o con muchas dimensiones?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d822aa",
   "metadata": {},
   "source": [
    "KNN es computacionalmente costoso en datasets grandes porque debe calcular la distancia a todos los puntos de entrenamiento para cada predicción. Además, en datos de alta dimensión (muchas variables), la distancia euclidiana pierde significado (mal de la dimensión), lo que puede reducir la precisión del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60d3830",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76827e64",
   "metadata": {},
   "source": [
    "respuesta aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707edf3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd6c9c",
   "metadata": {},
   "source": [
    "## Rúbrica de evaluación: Práctica KNN\n",
    "\n",
    "| Criterio | Descripción | Puntaje Máximo |\n",
    "|----------|-------------|----------------|\n",
    "| **1. Carga y exploración del dataset** | Carga correcta del archivo CSV, explicación de las variables y verificación de datos. | 15 pts |\n",
    "| **2. Implementación manual de KNN** | Código propio para calcular distancias euclidianas, selección de vecinos y votación mayoritaria. | 20 pts |\n",
    "| **3. Predicción individual (ejemplo aleatorio)** | Explicación clara del proceso paso a paso para un ejemplo de test. | 10 pts |\n",
    "| **4. Uso de scikit-learn (KNN)** | Entrenamiento y evaluación con `train_test_split`, comparación con el método manual. | 15 pts |\n",
    "| **5. Normalización y estandarización** | Aplicación correcta de Min-Max y Z-score, con cálculo de accuracy en cada caso. | 20 pts |\n",
    "| **6. Tabla comparativa de accuracies** | Presentación clara de los resultados y comparación entre métodos. | 10 pts |\n",
    "| **7. Reflexión y preguntas finales** | Respuestas a las preguntas de análisis planteadas (profundidad y claridad). | 10 pts |\n",
    "\n",
    "**Total: 100 pts**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
